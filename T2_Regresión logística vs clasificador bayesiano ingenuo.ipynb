{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos las bases de datos\n",
    "\n",
    "spam = pd.read_csv(\"http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_automatizado/data/spam.csv\", header=None)\n",
    "tumores= pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos las columnas de spam\n",
    "df_split = spam[0].str.split(expand=True)\n",
    "\n",
    "# Renombramos las columnas\n",
    "df_split.columns = [f'col_{i}' for i in range(df_split.shape[1]-1)] + ['target']\n",
    "\n",
    "# Convertimos las columnas a numéricas\n",
    "df_split = df_split.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_split['target']           # Variable dependiente\n",
    "X = df_split.drop(columns=['target'])  # Variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos la función de regresión logística\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class LogisticRegressionML:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estima los parámetros (pesos) por máxima verosimilitud\n",
    "        \"\"\"\n",
    "        self.clases = np.unique(y)\n",
    "        if len(self.clases) != 2:\n",
    "            raise ValueError(\"Este modelo solo soporta clasificación binaria.\")\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        self.n_atr = X.shape[1]\n",
    "\n",
    "        # Insertamos el bias (columna de unos)\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        w_init = np.zeros(X.shape[1])\n",
    "\n",
    "        def sigmoid(z):\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "\n",
    "        def loss(w):\n",
    "            z = X @ w\n",
    "            h = sigmoid(z)\n",
    "            epsilon = 1e-5\n",
    "            return -np.mean(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon))\n",
    "\n",
    "        def gradient(w):\n",
    "            z = X @ w\n",
    "            h = sigmoid(z)\n",
    "            return X.T @ (h - y) / n\n",
    "\n",
    "        res = minimize(fun=loss, x0=w_init, jac=gradient, method='BFGS')\n",
    "        self.w = res.x\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Calcula la probabilidad de la clase positiva (label 1)\n",
    "        \"\"\"\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        z = X @ self.w\n",
    "        probs = 1 / (1 + np.exp(-z))\n",
    "        return np.column_stack([1 - probs, probs])  # clase 0 y clase 1\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice la clase (0 o 1) según el umbral 0.5\n",
    "        \"\"\"\n",
    "        probs = self.predict_proba(X)\n",
    "        return (probs[:, 1] >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje promedio: 0.9703\n",
      "Desviación estándar: 0.0046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Definimos el clasificador\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegressionML())\n",
    "\n",
    "#Creamos el objeto de validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "#Calculamos los scores\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"Puntaje promedio: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar: {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje promedio: 0.9204\n",
      "Desviación estándar: 0.0081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Definimos el clasificador \n",
    "pipeline = make_pipeline(GaussianNB())\n",
    "\n",
    "# Creamos el objeto de validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "# Calculamos los scores\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"Puntaje promedio: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar: {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los nombres de las columnas\n",
    "column_names = [\n",
    "    \"ID_Muestra\", \"Grosor_Tumor\", \"Uniformidad_Tamaño_Celular\", \n",
    "    \"Uniformidad_Forma_Celular\", \"Adhesión_Marginal\", \"Tamaño_Célula_Epitelial\", \n",
    "    \"Núcleos_Desnudos\", \"Cromatina_Blanda\", \"Nucléolos_Normales\", \n",
    "    \"Mitosis_Celular\", \"Clase\"\n",
    "]\n",
    "\n",
    "# Asignamos los nombres de las columnas\n",
    "tumores.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitaremosw el ID de la muestra ya que no aporta información relevante\n",
    "tumores.drop(columns=\"ID_Muestra\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 eliminar las filas con valores nulos \n",
    "tumores['Núcleos_Desnudos'] = pd.to_numeric(tumores['Núcleos_Desnudos'], errors='coerce')  # Convierte a numérico y mete NaN donde hay '?'\n",
    "tumores.dropna(inplace=True)  # Elimina filas con NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapeamos la clase 2 a 0 y la clase 4 a 1\n",
    "tumores['Clase'] = tumores['Clase'].map({2: 0, 4: 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tumores['Clase']           # Variable dependiente\n",
    "X = tumores.drop(columns=['Clase'])  # Variables independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje promedio: 0.9679\n",
      "Desviación estándar: 0.0124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definimos el clasificador\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegressionML())\n",
    "\n",
    "#Creamos el objeto de validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "#Calculamos los scores\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"Puntaje promedio: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje promedio: 0.9621\n",
      "Desviación estándar: 0.0142\n"
     ]
    }
   ],
   "source": [
    "# Definimos el clasificador (sin escalado)\n",
    "pipeline = make_pipeline(GaussianNB())\n",
    "\n",
    "# Creamos el objeto de validación cruzada\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "# Calculamos los scores\n",
    "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"Puntaje promedio: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia uno hubiera pensado que el clasificador bayesiano ingenuo era una buena opción para clasificar los datos de spam, sin embargo, los resultados no fueron favorables para el modelo, el clasificador de regresión logística fue mejor tanto en la clasificación binaria de electos, con los tumores, como en el clasificador de lo que pudiera parecer la matriz de apariciones de textos.\n",
    "\n",
    "Esto se explica, ya que en ambos modelos el supuesto de independencia no se sostiene, ya que en el lenguaje la aparición de ciertas palabras cambia la probabilidad de ocurrencia de otras.\n",
    "\n",
    "Por lo tanto, vemos que la regresión logística funciona mejor como un elemento de segmentación binaria, dados los resultados, por ende sería el modelo que seleccionaríamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
